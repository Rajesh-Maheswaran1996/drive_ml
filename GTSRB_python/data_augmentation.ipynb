{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From explore.ipynb we can find the images that we can augment by rotating, flipping or mirroring.\n",
    "## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas:\n",
    "\n",
    "- Balance data by augmentation (Create more new pictures for underrepresented signs)\n",
    "- Assign different signs to different augmentation methods --> What is possible for which method?\n",
    "\n",
    "Signs:\n",
    "\n",
    "- 1) Speed Limit Zone beginning (30) --> Ordner: 00001\n",
    "- 2) Speed Limit Zone end (30) --> Ordner: KEINE DATEN bis jetzt\n",
    "- 3) Crosswalk --> Ordner: KEINE DATEN bis jetzt\n",
    "- 4) Barred area --> Ordner: KEINE DATEN bis jetzt\n",
    "- 5) Expressway beginning --> Ordner: KEINE DATEN bis jetzt\n",
    "- 6) Expressway end --> Ordner: KEINE DATEN bis jetzt\n",
    "- 7) Intersections STOP --> Ordner: 00014\n",
    "- 8) Intersections \"Vorfahrt gewähren\" --> Ordner: 00013\n",
    "- 9) Intersections \"Vorfahrtsstraße\"  --> Ordner: 00012\n",
    "- 10) Turn Left  --> Ordner: 00034\n",
    "- 11) Turn Right --> Do we need the counterparts here?  --> Ordner: 00033\n",
    "- 12) No-passing zone beginning --> Ordner: 00009\n",
    "- 13) No-passing zone end  --> Ordner: 00041\n",
    "- 14) Sharp turn left small --> Ordner: KEINE DATEN bis jetzt\n",
    "- 15) Sharp turn left large --> Ordner: KEINE DATEN bis jetzt\n",
    "- 16) Sharp turn right small --> Do we need the counterparts here? --> Ordner: KEINE DATEN bis jetzt\n",
    "- 17) Sharp turn right large --> Do we need the counterparts here? --> Ordner: KEINE DATEN bis jetzt\n",
    "- 18) Steep hill uphill grade --> Ordner: KEINE DATEN bis jetzt\n",
    "- 19) Steep hill downhill grade --> Ordner: KEINE DATEN bis jetzt\n",
    "\n",
    "Methods to augment data + for which signs applicable:\n",
    "\n",
    "-Flipping (horizontal/vertical)\n",
    "    \n",
    "    --> check possible invariances (e.g turn left signs) \n",
    "        and signs which can then be detected as other signs\n",
    "        \n",
    "    Horizontal:\n",
    "    9)\n",
    "    \n",
    "    Vertical:\n",
    "    5), 8), 9), 10) gets 11), 11) gets 10), 16) gets 17), 17) gets 16)\n",
    "    \n",
    "    Horizontal + Vertical:\n",
    "    9)\n",
    "\n",
    "-Rotating\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fippable_horizontally = [1, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dict list for signs ('name': 'folderdirectory')\n",
    "dict1 = {'Speed Limit Zone beginning (30)': '/00001', 'Speed Limit Zone end (30)': '-', 'Crosswalk': '-', 'Barred area': '-', 'Expressway beginning': '-', 'Expressway end': '-', 'Intersections STOP': '/00014', 'Intersections \"Vorfahrt gewähren\"': '/00013', 'Intersections \"Vorfahrtsstraße\"': '/00012', 'Turn Left': '/00034', 'Turn Right': '/00033', 'No-passing zone beginning': '/00009', 'No-passing zone end': '/00041', 'Sharp turn left small': '-', 'Sharp turn left large': '-', 'Sharp turn right small': '-', 'Sharp turn right large': '-', 'Steep hill uphill grade': '-', 'Steep hill downhill grade': '-'}\n",
    "\n",
    "#Print all sign types + link to the folders\n",
    "for el in dict1:\n",
    "    print (el, \"-->\", dict1[el], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count images per cell\n",
    "from gtsrb_loader.get_folderpath import get_folderpath\n",
    "import os, os.path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "path=get_folderpath('train');\n",
    "\n",
    "number_list = [] #element 0 is 0\n",
    "sign_list = []\n",
    "\n",
    "i = 0\n",
    "for k in iter(dict1.keys()):\n",
    "    if dict1[k] == '-':\n",
    "        number_files = 0\n",
    "    else:\n",
    "        changed_path=path+dict1[k]\n",
    "        list = os.listdir(changed_path) # dir is your directory path\n",
    "        number_files = len(list)\n",
    "    number_list.append(number_files)\n",
    "    sign_list.append(k)\n",
    "\n",
    "#Histogram\n",
    "plt.bar(range(len(number_list)), number_list)\n",
    "plt.xticks(range(1, len(number_list)))\n",
    "plt.title(\"Number of Files per folder\")\n",
    "plt.xlabel(\"Signs\")\n",
    "plt.ylabel(\"Number of Files\")\n",
    "plt.xticks(range(len(number_list)), sign_list, rotation='vertical')\n",
    "plt.show()\n",
    "\n",
    "#Legende\n",
    "for i in range(1, len(number_list)):\n",
    "    print (str(i) + \": \" + sign_list[i] + \" --> \" + str(number_list[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Augment cells using Keras "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, should do what is done here for our masks: https://keras.io/preprocessing/image/ <br/>\n",
    "So first, we create mask images for each of our size-equalized images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gtsrb_loader.load_data import load_data\n",
    "import numpy as np\n",
    "\n",
    "# load the images and classes\n",
    "X_train, y_train = load_data(path)\n",
    "X_train, y_train = np.array(X_train), np.array(y_train).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "images_df = pd.DataFrame()\n",
    "\n",
    "# load all csv label files, and save new image path to faciliate saving of the images in the next step\n",
    "for root, dirs_list, files_list in os.walk(path):\n",
    "    for file_name in files_list:\n",
    "        if file_name.endswith(\".csv\"):\n",
    "            file_name_path = os.path.join(root, file_name)\n",
    "            current_csv = pd.read_csv(file_name_path, sep=';')\n",
    "            for i,row in current_csv.iterrows():\n",
    "                new_name = os.path.join(os.path.dirname(os.path.dirname(root)),'Masks',os.path.basename(os.path.normpath(root)), current_csv.get_value(i,'Filename'))\n",
    "                current_csv.set_value(i,'Filename',new_name)\n",
    "            images_df = images_df.append(current_csv,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to generate mask images (255 at ROI, 0 at rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# top-level folder\n",
    "top_level_folder = os.path.dirname(os.path.dirname(images_df.get_value(1,'Filename')))\n",
    "if not os.path.isdir(top_level_folder):\n",
    "    os.mkdir(top_level_folder)\n",
    "    print('Created top-level folder', top_level_folder)\n",
    "\n",
    "# now: generate images and transform them\n",
    "for i,row in images_df.iterrows():\n",
    "    width = images_df.get_value(i,'Width')\n",
    "    height = images_df.get_value(i,'Height')\n",
    "    roi_x1 = images_df.get_value(i, 'Roi.X1')\n",
    "    roi_y1 = images_df.get_value(i, 'Roi.Y1')\n",
    "    roi_x2 = images_df.get_value(i, 'Roi.X2')\n",
    "    roi_y2 = images_df.get_value(i, 'Roi.Y2')\n",
    "    \n",
    "    im = Image.new('1', (width,height), (0))\n",
    "    draw = ImageDraw.Draw(im)\n",
    "    draw.rectangle([(roi_x1, roi_y1), (roi_x2, roi_y2)],fill=255)\n",
    "    \n",
    "    # make subfolders for each sign class if necessary\n",
    "    if not os.path.isdir(os.path.dirname(images_df.get_value(i,'Filename'))):\n",
    "        os.mkdir(os.path.dirname(images_df.get_value(i,'Filename')))\n",
    "    \n",
    "    # save created image at previously created path\n",
    "    im.save(images_df.get_value(i,'Filename'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we load both the images and the corresponding masks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "\n",
    "# load masks as numpy arrays\n",
    "shape_X = (X_train.shape[0], X_train.shape[1], X_train.shape[2],1)\n",
    "shape_Y = y_train.shape\n",
    "Mask_X_train = np.empty(shape_X)\n",
    "Mask_Y_train = np.empty(shape_Y)\n",
    "for i,row in images_df.iterrows():\n",
    "    Mask_X_train[i] = ndimage.imread(images_df.get_value(i,'Filename'),flatten=True).reshape(shape_X[1], shape_X[2], 1)\n",
    "    Mask_Y_train[i] = images_df.get_value(i,'ClassId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we augment using Keras data generators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# we create two instances with the same arguments \n",
    "data_gen_args = dict(featurewise_center=True,\n",
    "                     featurewise_std_normalization=True,\n",
    "                     rotation_range=90.,\n",
    "                     width_shift_range=0.1,\n",
    "                     height_shift_range=0.1,\n",
    "                     zoom_range=0.2)\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "print('Created image data generators')\n",
    "    \n",
    "# Provide the same seed and keyword arguments to the fit and flow methods\n",
    "seed = 1\n",
    "print('Fitting data generators')\n",
    "image_datagen.fit(X_train, augment=True, seed=seed)\n",
    "mask_datagen.fit(Mask_X_train, augment=True, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rename our previously defined paths for clarity\n",
    "image_path = path\n",
    "mask_path = top_level_folder\n",
    "\n",
    "image_path_out = os.path.join(os.path.dirname(image_path),'Images_Augmented')\n",
    "if not os.path.isdir(image_path_out):\n",
    "    os.mkdir(image_path_out)\n",
    "    print('Created folder for augmented images at:', image_path_out)\n",
    "else:\n",
    "    print('Using existing augmented image folder at:', image_path_out)\n",
    "\n",
    "if not os.path.isdir(os.path.join(image_path_out,'Images')):\n",
    "    os.mkdir(os.path.join(image_path_out,'Images'))\n",
    "if not os.path.isdir(os.path.join(image_path_out,'Masks')):\n",
    "    os.mkdir(os.path.join(image_path_out,'Masks'))  \n",
    "\n",
    "# set this to specify how many images you want to process at once\n",
    "batching_size = 32;   \n",
    "# set this to specify how many times you want to process that many images\n",
    "repeats = 1\n",
    "\n",
    "# flow and directly augment to folders\n",
    "i = 0\n",
    "for batch in image_datagen.flow(X_train, batch_size=batching_size,\n",
    "                          save_to_dir=os.path.join(image_path_out,'Images'), save_prefix='mod', save_format='ppm'):\n",
    "    i += 1\n",
    "    if i > repeats:\n",
    "        break\n",
    "\n",
    "# augment masks\n",
    "i = 0\n",
    "for batch in mask_datagen.flow(Mask_X_train, batch_size=batching_size,\n",
    "                          save_to_dir=os.path.join(image_path_out,'Masks'), save_prefix='mod', save_format='ppm'):\n",
    "    i += 1\n",
    "    if i > repeats:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how you would then train a model with this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "# combine generators into one which yields image and masks\n",
    "image_generator = image_datagen.flow(X_train)\n",
    "mask_generator = mask_datagen.flow(Mask_X_train)\n",
    "train_generator = zip(image_generator, mask_generator)\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=2000,\n",
    "    epochs=50)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
