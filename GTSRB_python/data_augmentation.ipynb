{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From explore.ipynb we can find the images that we can augment by rotating, flipping or mirroring.\n",
    "## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas:\n",
    "\n",
    "- Balance data by augmentation (Create more new pictures for underrepresented signs)\n",
    "- Assign different signs to different augmentation methods --> What is possible for which method?\n",
    "\n",
    "Signs:\n",
    "\n",
    "- 1) Speed Limit Zone beginning (30) --> Ordner: 00001\n",
    "- 2) Speed Limit Zone end (30) --> Ordner: KEINE DATEN bis jetzt\n",
    "- 3) Crosswalk --> Ordner: KEINE DATEN bis jetzt\n",
    "- 4) Barred area --> Ordner: KEINE DATEN bis jetzt\n",
    "- 5) Expressway beginning --> Ordner: KEINE DATEN bis jetzt\n",
    "- 6) Expressway end --> Ordner: KEINE DATEN bis jetzt\n",
    "- 7) Intersections STOP --> Ordner: 00014\n",
    "- 8) Intersections \"Vorfahrt gewähren\" --> Ordner: 00013\n",
    "- 9) Intersections \"Vorfahrtsstraße\"  --> Ordner: 00012\n",
    "- 10) Turn Left  --> Ordner: 00034\n",
    "- 11) Turn Right --> Do we need the counterparts here?  --> Ordner: 00033\n",
    "- 12) No-passing zone beginning --> Ordner: 00009\n",
    "- 13) No-passing zone end  --> Ordner: 00041\n",
    "- 14) Sharp turn left small --> Ordner: KEINE DATEN bis jetzt\n",
    "- 15) Sharp turn left large --> Ordner: KEINE DATEN bis jetzt\n",
    "- 16) Sharp turn right small --> Do we need the counterparts here? --> Ordner: KEINE DATEN bis jetzt\n",
    "- 17) Sharp turn right large --> Do we need the counterparts here? --> Ordner: KEINE DATEN bis jetzt\n",
    "- 18) Steep hill uphill grade --> Ordner: KEINE DATEN bis jetzt\n",
    "- 19) Steep hill downhill grade --> Ordner: KEINE DATEN bis jetzt\n",
    "\n",
    "Methods to augment data + for which signs applicable:\n",
    "\n",
    "-Flipping (horizontal/vertical)\n",
    "    \n",
    "    --> check possible invariances (e.g turn left signs) \n",
    "        and signs which can then be detected as other signs\n",
    "        \n",
    "    Horizontal:\n",
    "    9)\n",
    "    \n",
    "    Vertical:\n",
    "    5), 8), 9), 10) gets 11), 11) gets 10), 16) gets 17), 17) gets 16)\n",
    "    \n",
    "    Horizontal + Vertical:\n",
    "    9)\n",
    "\n",
    "-Rotating\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fippable_horizontally = [1, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dict list for signs ('name': 'folderdirectory')\n",
    "dict1 = {'Speed Limit Zone beginning (30)': '/00001', 'Speed Limit Zone end (30)': '-', 'Crosswalk': '-', 'Barred area': '-', 'Expressway beginning': '-', 'Expressway end': '-', 'Intersections STOP': '/00014', 'Intersections \"Vorfahrt gewähren\"': '/00013', 'Intersections \"Vorfahrtsstraße\"': '/00012', 'Turn Left': '/00034', 'Turn Right': '/00033', 'No-passing zone beginning': '/00009', 'No-passing zone end': '/00041', 'Sharp turn left small': '-', 'Sharp turn left large': '-', 'Sharp turn right small': '-', 'Sharp turn right large': '-', 'Steep hill uphill grade': '-', 'Steep hill downhill grade': '-'}\n",
    "\n",
    "#Print all sign types + link to the folders\n",
    "for el in dict1:\n",
    "    print (el, \"-->\", dict1[el], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count images per cell\n",
    "from gtsrb_loader.get_folderpath import get_folderpath\n",
    "import os, os.path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "path=get_folderpath('train');\n",
    "\n",
    "number_list = [] #element 0 is 0\n",
    "sign_list = []\n",
    "\n",
    "i = 0\n",
    "for k in iter(dict1.keys()):\n",
    "    if dict1[k] == '-':\n",
    "        number_files = 0\n",
    "    else:\n",
    "        changed_path=path+dict1[k]\n",
    "        list = os.listdir(changed_path) # dir is your directory path\n",
    "        number_files = len(list)\n",
    "    number_list.append(number_files)\n",
    "    sign_list.append(k)\n",
    "\n",
    "#Histogram\n",
    "plt.bar(range(len(number_list)), number_list)\n",
    "plt.xticks(range(1, len(number_list)))\n",
    "plt.title(\"Number of Files per folder\")\n",
    "plt.xlabel(\"Signs\")\n",
    "plt.ylabel(\"Number of Files\")\n",
    "plt.xticks(range(len(number_list)), sign_list, rotation='vertical')\n",
    "plt.show()\n",
    "\n",
    "#Legende\n",
    "for i in range(1, len(number_list)):\n",
    "    print (str(i) + \": \" + sign_list[i] + \" --> \" + str(number_list[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Augment cells using Keras "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, should do what is done here for our masks: https://keras.io/preprocessing/image/ <br/>\n",
    "So first, we create mask images for each of our size-equalized images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtsrb_loader.load_data import load_data\n",
    "import numpy as np\n",
    "\n",
    "# load the images and classes\n",
    "X_train, y_train = load_data(path)\n",
    "X_train, y_train = np.array(X_train), np.array(y_train).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# load all csv label files\n",
    "images_df = pd.read_csv(os.path.join(path, '00000', 'GT-00000.csv'), sep=';')\n",
    "\n",
    "for root, dirs_list, files_list in os.walk(path):\n",
    "    for file_name in files_list:\n",
    "        if file_name.endswith(\".csv\"):\n",
    "            if file_name == 'GT-00000.csv':\n",
    "                continue\n",
    "            file_name_path = os.path.join(root, file_name)\n",
    "            images_df.append(pd.read_csv(file_name_path, sep=';'))\n",
    "\n",
    "print(images_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to generate mask images (255 at ROI, 0 at rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now: generate images and transform them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will just use the image generator with required settings to generate augmented data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we create two instances with the same arguments\n",
    "data_gen_args = dict(featurewise_center=True,\n",
    "                     featurewise_std_normalization=True,\n",
    "                     rotation_range=90.,\n",
    "                     width_shift_range=0.1,\n",
    "                     height_shift_range=0.1,\n",
    "                     zoom_range=0.2)\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "# Provide the same seed and keyword arguments to the fit and flow methods\n",
    "seed = 1\n",
    "image_datagen.fit(images, augment=True, seed=seed)\n",
    "mask_datagen.fit(masks, augment=True, seed=seed)\n",
    "\n",
    "image_generator = image_datagen.flow_from_directory(\n",
    "    path,\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "mask_generator = mask_datagen.flow_from_directory(\n",
    "    os.path.join(path,masks),\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "# combine generators into one which yields image and masks\n",
    "train_generator = zip(image_generator, mask_generator)\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=2000,\n",
    "    epochs=50)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
