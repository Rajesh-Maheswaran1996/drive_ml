{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mlp\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert dict to Yolo format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_name_carolo_trans = {\n",
    "\t0: 0,\n",
    "\t1: 1,\n",
    "\t2: 2,\n",
    "\t3: 3,\n",
    "\t4: 4,\n",
    "\t5: 5,\n",
    "\t9: 6,\n",
    "\t12: 7,\n",
    "\t13: 8,\n",
    "\t14: 9,\n",
    "\t33: 10,\n",
    "\t34: 11,\n",
    "\t38: 12,\n",
    "\t41: 13,\n",
    "\t43: 30,\n",
    "\t100: 14,\n",
    "\t101: 15,\n",
    "\t102: 16,\n",
    "\t103: 17,\n",
    "\t104: 18,\n",
    "\t105: 19,\n",
    "\t106: 20,\n",
    "\t107: 21,\n",
    "\t108: 22,\n",
    "\t109: 23,\n",
    "\t110: 24,\n",
    "\t111: 25,\n",
    "\t112: 26,\n",
    "\t113: 27,\n",
    "\t114: 28,\n",
    "\t115: 29\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_name_carolo_trans_pretrain = {\n",
    "\t0: 0,\n",
    "\t1: 0,\n",
    "\t2: 0,\n",
    "\t3: 0,\n",
    "\t4: 0,\n",
    "\t5: 0,\n",
    "\t9: 1,\n",
    "\t12: 2,\n",
    "\t13: 3,\n",
    "\t14: 4,\n",
    "\t33: 5,\n",
    "\t34: 6,\n",
    "\t38: 7,\n",
    "\t41: 8,\n",
    "\t43: 22,\n",
    "\t100: 9,\n",
    "\t101: 10,\n",
    "\t102: 11,\n",
    "\t103: 12,\n",
    "\t104: 13,\n",
    "\t105: 14,\n",
    "\t106: 15,\n",
    "\t107: 16,\n",
    "\t108: 17,\n",
    "\t109: 18,\n",
    "\t110: 19,\n",
    "\t111: 20,\n",
    "\t112: 0,\n",
    "\t113: 0,\n",
    "\t114: 0,\n",
    "\t115: 21\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_name_carolo_dict_new = {\n",
    "    0: '20 Zone Anfang (speed limit 20 start)',\n",
    "\t1: '30 Zone Anfang (speed limit 30 start)',\n",
    "\t2: '50 Zone Anfang (speed limit 50 start)',\n",
    "\t3: '60 Zone Anfang (speed limit 60 start)',\n",
    "\t4: '70 Zone Anfang (speed limit 70 start)',\n",
    "\t5: '80 Zone Anfang (speed limit 80 start)',\n",
    "\t6: 'Absolutes Ueberholverbot Anfang (no passing zone start)',\n",
    "\t7: 'Vorfahrtstrasse (priority on next intersections)',\n",
    "\t8: 'Vorfahrt Gewaehren (give way to incoming)',\n",
    "\t9: 'Stop Zeichen (stop for at least 3 sec)',\n",
    "\t10: 'Vorgeschriebene Fahrtrichtung Rechts (turn right on intersection)',\n",
    "\t11: 'Vorgeschriebene Fahrtrichtung Links (turn left on intersection)',\n",
    "\t12: 'Vorgeschriebene Vorbeifahrt rechts (pass by on right)',\n",
    "\t13: 'Absolutes Ueberholverbot Ende (no passing zone end)',\n",
    "\t30: 'Nullklasse (zero class)',\n",
    "\t14: 'Gegenverkehr Vorrang gewaehren (Barred area, let oncoming pass)',\n",
    "\t15: 'Zone Ende (end of speed limit)',\n",
    "\t16: 'Fussgaengerueberweg (crosswalk)',\n",
    "\t17: 'Richtungstafel Kurve links (sharp turn left)',\n",
    "\t18: 'Richtungstafel Kurve links (even sharper turn left)',\n",
    "\t19: 'Richtungstafel Kurve rechts (sharp turn right)',\n",
    "\t20: 'Richtungstafel Kurve rechts (even sharper turn right)',\n",
    "\t21: 'Gefaelle 10% (downhill 10%)',\n",
    "\t22: 'Steigung 10% (uphill 10%)',\n",
    "\t23: 'Parken Bereich (parking zone)',\n",
    "\t24: 'Kraftfahrtstrasse Anfang (expressway begin)',\n",
    "\t25: 'Kraftfahrtstrasse Ende (expressway end)',\n",
    "\t26: '10 Zone Anfang (speed limit 10 start)',\n",
    "\t27: '40 Zone Anfang (speed limit 40 start)',\n",
    "\t28: '90 Zone Anfang (speed limit 90 start)',\n",
    "\t29: 'Pedestrian'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_coordinates(x1,y1,x2,y2,dimX,dimY):\n",
    "    centerX=(x1+x2)/2\n",
    "    centerY=(y1+y2)/2\n",
    "    width=x2-x1\n",
    "    height=y2-y1\n",
    "    #to relative values:\n",
    "    centerX=centerX/dimX\n",
    "    centerY=centerY/dimY\n",
    "    width=width/dimX\n",
    "    height=height/dimY\n",
    "    \n",
    "    return centerX,centerY,width,height\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zerofix(string):\n",
    "    s=string.split(\"/\")[-1].split(\"e\")[-1]\n",
    "    rest=string.split(\"/\")[:-1]\n",
    "    result=\"/\".join(rest)\n",
    "    i=int(s)-1\n",
    "    st=result+'/frame'+str(i).zfill(4)\n",
    "    return st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced(labelcounter, files_per_class):\n",
    "    m=np.min(labelcounter)\n",
    "    filelist=[]\n",
    "    for j,files_class in enumerate(files_per_class):\n",
    "        shuffle(files_class)\n",
    "        for i,s in enumerate(files_class):\n",
    "            if m-1<=i:\n",
    "                break;\n",
    "            if s not in filelist:    \n",
    "                filelist.append(s)\n",
    "        print(j,i)\n",
    "    return filelist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating labelfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafiles=[]\n",
    "basepath='/data/Images/'\n",
    "#datafiles.append(basepath+'test_environment')\n",
    "datafiles.append(basepath+'signs001_manually_labeled')\n",
    "datafiles.append(basepath+'signs003_manually_labeled')\n",
    "datafiles.append(basepath+'signs004_manually_labeled')\n",
    "datafiles.append(basepath+'signs006_bosch_manually_labeled')\n",
    "datafiles.append(basepath+'2019-01-09-13-00-05')\n",
    "datafiles.append(basepath+'2019-01-09-13-01-41')\n",
    "datafiles.append(basepath+'2019-01-09-13-05-43')\n",
    "datafiles.append(basepath+'2019-01-09-13-24-37')\n",
    "datafiles.append(basepath+'2019-01-09-13-55-01')\n",
    "datafiles.append(basepath+'2019-01-20-15-59-41')\n",
    "\n",
    "# Zone fillers\n",
    "datafiles.append(basepath+'VID_20190125_181012')\n",
    "datafiles.append(basepath+'VID_20190125_181207')\n",
    "datafiles.append(basepath+'VID_20190125_181313')\n",
    "datafiles.append(basepath+'VID_20190125_181630')\n",
    "datafiles.append(basepath+'VID_20190125_181902')\n",
    "\n",
    "## Blur\n",
    "datafiles.append(basepath+'signs001_manually_labeled_blur')\n",
    "datafiles.append(basepath+'signs003_manually_labeled_blur')\n",
    "datafiles.append(basepath+'signs004_manually_labeled_blur')\n",
    "datafiles.append(basepath+'signs006_bosch_manually_labeled_blur')\n",
    "datafiles.append(basepath+'2019-01-09-13-00-05_blur')\n",
    "datafiles.append(basepath+'2019-01-09-13-01-41_blur')\n",
    "datafiles.append(basepath+'2019-01-09-13-05-43_blur')\n",
    "datafiles.append(basepath+'2019-01-09-13-24-37_blur')\n",
    "datafiles.append(basepath+'2019-01-09-13-55-01_blur')\n",
    "datafiles.append(basepath+'2019-01-20-15-59-41_blur')\n",
    "datafiles.append(basepath+'VID_20190125_181012_blur')\n",
    "datafiles.append(basepath+'VID_20190125_181207_blur')\n",
    "datafiles.append(basepath+'VID_20190125_181313_blur')\n",
    "datafiles.append(basepath+'VID_20190125_181630_blur')\n",
    "datafiles.append(basepath+'VID_20190125_181902_blur')\n",
    "\n",
    "#datafiles.append(basepath+'bosch_2018_16_36') Bug in labels\n",
    "datafiles.append(basepath+'bosch_2018_17_08')\n",
    "datafiles.append(basepath+'bosch_2018_17_24')\n",
    "datafiles.append(basepath+'bosch_2018_17_54')\n",
    "\n",
    "#\n",
    "#datafiles.append(basepath+'Datasets/GTSDB')\n",
    "#datafiles.append(basepath+'Datasets/STS')\n",
    "#datafiles.append(basepath+'Datasets/BTSDB')\n",
    "#datafiles.append(basepath+'Datasets/rtsd-public/detection/rtsd-d1-frames')\n",
    "#datafiles.append(basepath+'Datasets/rtsd-public/detection/rtsd-d2-frames')\n",
    "#datafiles.append(basepath+'Datasets/rtsd-public/detection/rtsd-d3-frames')\n",
    "\n",
    "\n",
    "#zerobase=['bosch_2018_16_36','bosch_2018_17_54','bosch_2018_17_24','bosch_2018_17_08','2019-01-09-13-00-05','2019-01-09-13-01-41','2019-01-09-13-05-43','2019-01-09-13-24-37','2019-01-09-13-55-01']\n",
    "zerobase=[]\n",
    "jpglist=['VID_20190125_181902','VID_20190125_181630','VID_20190125_181313','VID_20190125_181207','VID_20190125_181012','Datasets/rtsd-public/detection/rtsd-d3-frames','Datasets/rtsd-public/detection/rtsd-d2-frames','Datasets/rtsd-public/detection/rtsd-d1-frames','bosch_2018_17_54','bosch_2018_17_24','bosch_2018_17_08','2019-01-09-13-00-05','2019-01-09-13-01-41','2019-01-09-13-05-43','2019-01-09-13-24-37','2019-01-09-13-55-01','2019-01-20-15-59-41', 'Datasets/STS']\n",
    "ppmlist=['Datasets/GTSDB']\n",
    "jp2list=['Datasets/BTSDB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files=[]\n",
    "oldFile=None\n",
    "num_Zero=2000\n",
    "counter=0\n",
    "frames = []\n",
    "zero_class=sign_name_carolo_trans.get(43)\n",
    "labelcounter=np.zeros((31,))\n",
    "files_per_class=np.empty((31,),dtype=object)\n",
    "for i,v in enumerate(files_per_class): files_per_class[i]=[]\n",
    "    \n",
    "#iterate over all folder from datasets\n",
    "for folder in datafiles:\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.csv'):\n",
    "            print(filename)\n",
    "            df = pd.read_csv(folder+'/'+filename)\n",
    "            df['ClassId'].replace(sign_name_carolo_trans, inplace=True)\n",
    "            for index, row in df.iterrows():           \n",
    "                classid=int(row['ClassId'])\n",
    "                centerX,centerY,width,height=transform_coordinates(row['Roi.X1'],row['Roi.Y1'],row['Roi.X2'],row['Roi.Y2'],row['Width'],row['Height'])\n",
    "                #file=row['Filename'].split('.')[0]\n",
    "                file=''.join(row['Filename'].split('.')[0:-1])\n",
    "                if any(st in folder for st in zerobase):\n",
    "                    file=zerofix(file)\n",
    "                    file=file.split('/')[-1]\n",
    "                labelcounter[classid]+=1\n",
    "                if classid!=zero_class:\n",
    "                    if file==oldFile:\n",
    "                        #print(centerX,centerY,width,height)\n",
    "                        f = open(folder+'/'+file+'.txt',\"a\") \n",
    "                        f.write(str(classid)+' '+str(centerX)+' '+str(centerY)+' '+str(width)+' '+str(height)+'\\n')\n",
    "                        f.close()\n",
    "                        files_per_class[classid].append(folder+'/'+file)\n",
    "                    else:\n",
    "                        f = open(folder+'/'+file+'.txt',\"w\") \n",
    "                        f.write(str(classid)+' '+str(centerX)+' '+str(centerY)+' '+str(width)+' '+str(height)+'\\n')\n",
    "                        f.close()\n",
    "                        #print(folder+'/'+file)\n",
    "                        files.append(folder+'/'+file)\n",
    "                        files_per_class[classid].append(folder+'/'+file)\n",
    "                elif classid==20 and counter<num_Zero:\n",
    "                    f = open(folder+'/'+file+'.txt',\"w\") \n",
    "                    f.close()\n",
    "                    counter+=1\n",
    "                    files.append(folder+'/'+file)\n",
    "                    files_per_class[classid].append(folder+'/'+file)\n",
    "                oldFile=file\n",
    "                \n",
    "                #frames_added_april.append(pd.read_csv(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sign_name_carolo_dict_new)):\n",
    "    print(str(labelcounter[i])+'  '+sign_name_carolo_dict_new[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test=np.empty((31,),dtype=object)\n",
    "for i,v in enumerate(test): test[i]=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,e in enumerate(files_per_class[0]):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance=False\n",
    "if balance==True:\n",
    "    files=balanced(labelcounter,files_per_class)\n",
    "    print(\"Minimum Labels is:\")\n",
    "    print(np.min(labelcounter))\n",
    "    print(\"Dataset is balanced to that number\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train,X_test=train_test_split(files, shuffle=False)\n",
    "\n",
    "num_of_rows = round((len(files)) * 0.8)\n",
    "files_np=np.array(files)\n",
    "np.random.shuffle(files_np) \n",
    "X_train= files_np[:num_of_rows] \n",
    "X_test = files_np[num_of_rows:] \n",
    "\n",
    "file = open(basepath+'train.txt',\"w\")\n",
    "for line in X_train:\n",
    "    #if any(st in line for st in zerobase):\n",
    "     #   line=zerofix(line)\n",
    "    if any(st in line for st in jpglist):\n",
    "        file.write(str(line)+'.jpg\\n')\n",
    "    elif any(st in line for st in ppmlist):\n",
    "        file.write(str(line)+'.ppm\\n')\n",
    "    elif any(st in line for st in jp2list):\n",
    "        file.write(str(line)+'.jp2\\n')\n",
    "    else:\n",
    "        file.write(str(line)+'.png\\n')\n",
    "file.close()\n",
    "    \n",
    "file = open(basepath+'test.txt',\"w\")\n",
    "for line in X_test:\n",
    "    #if any(st in line for st in zerobase):\n",
    "    #    line=zerofix(line)\n",
    "    if any(st in line for st in jpglist):\n",
    "        file.write(str(line)+'.jpg\\n')\n",
    "    elif any(st in line for st in ppmlist):\n",
    "        file.write(str(line)+'.ppm\\n')\n",
    "    elif any(st in line for st in jp2list):\n",
    "        file.write(str(line)+'.jp2\\n')\n",
    "    else:\n",
    "        file.write(str(line)+'.png\\n')\n",
    "file.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(basepath+'signs.names',\"w\")\n",
    "for num in range(len(sign_name_carolo_trans)-1):\n",
    "    file.write(str(sign_name_carolo_dict_new.get(num)))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../sign_recognition/dict/sign_names_dict.pkl', 'rb') as f:\n",
    "    sign_names = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sign_name_carolo_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
