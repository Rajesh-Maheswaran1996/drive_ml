{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export locations of the scripts\n",
    "from export_locations import export_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"../sign_recognition/dict/\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sign_names_dict import sign_name_carolo_dict\n",
    "\n",
    "def convert_to_carolo_csv(df, conversion_dict):\n",
    "    df = df[df['ClassId'].isin(conversion_dict)]\n",
    "    df['ClassId'].replace(conversion_dict, inplace=True)\n",
    "    display(df.head())\n",
    "    df_visual = df.copy()\n",
    "    df_visual['ClassId'].replace(sign_name_carolo_dict, inplace=True)\n",
    "    grouped_classes = df_visual.groupby('ClassId').count()['Roi.X1']  # Group the dataframe by classes.\n",
    "    grouped_classes.plot(kind='bar', figsize=(9,4),  title='Amount of Instances per Class', legend=False)\n",
    "    plt.show()\n",
    "    return df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GTSDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sign_names_dict import sign_name_GTSRB_full_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/data/Images/Datasets/GTSDB/gt.csv')\n",
    "df_named = df.copy()\n",
    "df_named['ClassId'].replace(sign_name_GTSRB_full_dict, inplace=True)\n",
    "df_named.head()  # prints top 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_classes = df_named.groupby('ClassId').count()['Roi.X1']  # Group the dataframe by classes.\n",
    "grouped_classes.plot(kind='bar', figsize=(9,4),  title='Amount of Instances per Class', legend=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sign_names_dict import gtsrb_to_carolo\n",
    "df.head()\n",
    "df = df[df['ClassId'].isin(gtsrb_to_carolo)]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_named_cleaned = df.copy()\n",
    "df_named_cleaned['ClassId'].replace(sign_name_carolo_dict, inplace=True)\n",
    "grouped_classes = df_named_cleaned.groupby('ClassId').count()['Roi.X1']  # Group the dataframe by classes.\n",
    "grouped_classes.plot(kind='bar', figsize=(9,4),  title='Amount of Instances per Class', legend=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(export_locations['GTSDB'], sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LISA and LISA-TS-Extended\n",
    "\n",
    "Only usable signs are the stop signs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_LISA_to_carolo(df):\n",
    "    carolo_df = df[['Filename', 'Upper left corner X', 'Upper left corner Y', 'Lower right corner X', 'Lower right corner Y', 'Annotation tag']].copy()\n",
    "    carolo_df.rename(\n",
    "      columns={\n",
    "        'Upper left corner X' : 'Roi.X1',\n",
    "        'Upper left corner Y' : 'Roi.Y1',\n",
    "        'Lower right corner X' : 'Roi.X2',\n",
    "        'Lower right corner Y' : 'Roi.Y2',\n",
    "        'Annotation tag' : 'ClassId'\n",
    "      },\n",
    "      inplace=True\n",
    "    )\n",
    "    return carolo_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LISA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/data/Images/Datasets/LISA/TS/LISA_filtered.csv')\n",
    "df.head()  # prints top 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sign_names_dict import LISA_to_carolo\n",
    "lisa_df = convert_LISA_to_carolo(df)\n",
    "lisa_df = convert_to_carolo_csv(lisa_df, LISA_to_carolo)\n",
    "lisa_df.to_csv(export_locations['LISA'], sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('LISA Contains', lisa_df['ClassId'].size, 'stop signs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LISA-Extended\n",
    "\n",
    "Same deal, just stop signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lisa_extended_df = pd.read_csv('/data/Images/Datasets/LISA/training/allTrainingAnnotations.csv')\n",
    "lisa_extended_df.head()  # prints top 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lisa_extended_df.to_csv(export_locations['LISA_EXTENDED'], sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('LISA Extended Contains', lisa_extended_df['ClassId'].size, 'stop signs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BTSD\n",
    "\n",
    "Contains most of our classes except for turn signals and speed zones.\n",
    "\n",
    "## Testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/data/Images/Datasets/BTSDB/BelgiumTSD_annotations/BTSD_testing_GTclear.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove trailing class added by comma and superclass\n",
    "df = df.drop(['SuperclassId', 'Unnamed: 7'], axis=1)\n",
    "df['Filename'] = df['Filename'].str.replace('.jp2', '.png')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sign_names_dict import BTSD_to_carolo\n",
    "btsd_test_df = convert_to_carolo_csv(df, BTSD_to_carolo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/data/Images/Datasets/BTSDB/BelgiumTSD_annotations/BTSD_training_GTclear.txt')\n",
    "df = df.drop(['SuperclassId', 'Unnamed: 7'], axis=1)\n",
    "df['Filename'] = df['Filename'].str.replace('.jp2', '.png')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sign_names_dict import BTSD_to_carolo\n",
    "btsd_train_df = convert_to_carolo_csv(df, BTSD_to_carolo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_btsd_df = pd.concat([btsd_train_df, btsd_test_df])\n",
    "combined_btsd_df.to_csv(export_locations['BTSD_TRAINING'], sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Swedish Traffic Sign Dataset (STS)\n",
    "\n",
    "Sweden also uses yellow as base, same as US, but some more usable signs overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sign_names_dict import STS_to_carolo\n",
    "\n",
    "def read_sts_annotation(filepath):\n",
    "    data = []\n",
    "    with open(filepath, 'r') as file:\n",
    "        text = file.read() \n",
    "    lines = text.split('\\n')\n",
    "    for line in lines[0:-2]:\n",
    "        split_line = line.split(':')\n",
    "        filename = str(split_line[0]).lstrip()\n",
    "        if filename == '':\n",
    "            print('ERROR: file incorrect!')\n",
    "            break\n",
    "\n",
    "        if split_line[1] == '':\n",
    "            continue\n",
    "        else:\n",
    "            split_signs = split_line[1].split(';')\n",
    "            for split_sign in split_signs[0:-2]:\n",
    "                sign_info = split_sign.split(',')\n",
    "                \n",
    "                # skip misc signs with no info\n",
    "                if sign_info[0] == 'MISC_SIGNS':\n",
    "                    continue\n",
    "                \n",
    "                sign_name = str(sign_info[-1]).lstrip()\n",
    "                # tl positions are second\n",
    "                x1 = float(sign_info[-3].lstrip())\n",
    "                y1 = float(sign_info[-4].lstrip())\n",
    "                x2 = float(sign_info[-5].lstrip())\n",
    "                y2 = float(sign_info[-6].lstrip())\n",
    "                data.append([filename, x1, y1, x2, y2, sign_name])\n",
    "                \n",
    "    df = pd.DataFrame(data, columns=['Filename','Roi.X1','Roi.Y1','Roi.X2','Roi.Y2','ClassId'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_sts_annotation('/data/Images/Datasets/STS/annotations_1.txt')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts_annotations_1_df = convert_to_carolo_csv(df, STS_to_carolo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_sts_annotation('/data/Images/Datasets/STS/annotations_2.txt')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts_annotations_2_df = convert_to_carolo_csv(df, STS_to_carolo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_sts_df = pd.concat([sts_annotations_1_df, sts_annotations_2_df])\n",
    "combined_sts_df.to_csv(export_locations['STS'], sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset of Italian Traffic Signs (DITS)\n",
    "\n",
    "For some reason no annotations are uploaded for the detection subset and detection subset is more like GTSRB (cropped window) even though in their paper it looks fine (and in the test data) and in the paper they promise to \"improve soon\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Russian Traffic Sign Dataset \n",
    "\n",
    "Merged subclass annotations into single file for each of the three dataset-parts, bash script is in the dataset root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def parse_rtsb_filenames(filepath):\n",
    "    files = []\n",
    "    with open(os.path.join('/data/Images/Datasets/rtsd-public/detection/', filepath, 'train_filenames.txt'), 'r') as f:\n",
    "        files += f.read().splitlines()\n",
    "    with open(os.path.join('/data/Images/Datasets/rtsd-public/detection/', filepath, 'test_filenames.txt'), 'r') as f:\n",
    "        files += f.read().splitlines()\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_rtsb_df(rtsb_csv_path):\n",
    "    df = pd.read_csv(rtsb_csv_path)\n",
    "    df.rename(\n",
    "      columns={\n",
    "        'x_from': 'Roi.X1',\n",
    "        'y_from' : 'Roi.Y1',\n",
    "        'sign_class' : 'ClassId',\n",
    "        'width' : 'Width',\n",
    "        'height' : 'Height',\n",
    "        'filename' : 'Filename',\n",
    "      },\n",
    "      inplace=True\n",
    "    )\n",
    "    df['Roi.X2'] = df['Roi.X1'] + df['Width']\n",
    "    df['Roi.Y2'] = df['Roi.Y1'] + df['Height']\n",
    "    df['Width']=1280\n",
    "    df['Height']=720\n",
    "    df = df[['Filename', 'Width', 'Height', 'Roi.X1', 'Roi.Y1', 'Roi.X2', 'Roi.Y2','ClassId']]\n",
    "    display(df.head())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sign_names_dict import rtsd_to_carolo\n",
    "\n",
    "rtsb_merged_paths = ['/data/Images/Datasets/rtsd-public/detection/rtsd-d1-gt/merged.csv',\n",
    "                     '/data/Images/Datasets/rtsd-public/detection/rtsd-d2-gt/merged.csv',\n",
    "                     '/data/Images/Datasets/rtsd-public/detection/rtsd-d3-gt/merged.csv']\n",
    "\n",
    "rtsb_folder_prefixes = ['rtsd-d1-', 'rtsd-d2-', 'rtsd-d3-']\n",
    "\n",
    "# since all datasets contain all labels and just the image name lists differ for each subdataset, we display only once\n",
    "annotation_dfs = []\n",
    "for rtsb_merged_path, rtsb_folder_prefix in zip(rtsb_merged_paths, rtsb_folder_prefixes):\n",
    "    print('Processing csv: {} corresponding to folder: {}'.format(rtsb_merged_path, rtsb_folder_prefix))\n",
    "    df = convert_rtsb_df(rtsb_merged_paths[0])\n",
    "    filenames = parse_rtsb_filenames(rtsb_folder_prefix + 'gt')\n",
    "    df = df[df['Filename'].isin(filenames)]\n",
    "    # todo: filter filenames so that only the ones in the set remain\n",
    "    df['Filename'] = rtsb_folder_prefix + 'frames/' + df['Filename'].astype('str')\n",
    "    df = convert_to_carolo_csv(df, rtsd_to_carolo)\n",
    "    annotation_dfs.append(df.copy())\n",
    "\n",
    "combined_rtsd_df = pd.concat(annotation_dfs)\n",
    "combined_rtsd_df.to_csv(export_locations['RTSD'], sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Mapillary Traffic Sign Detection Dataset (MTSD)\n",
    " \n",
    " Contains pretty much all traffic signs from the stvo, so we can just use these labels directly. \n",
    " \n",
    " Images are annotated in a per-image json format.\n",
    " \n",
    " The class list is quite hidden, but can be found [here](https://www.mapillary.com/developer/api-documentation/#traffic-signs). Traffic signs are split into \"appearance groups\". These are not fully exhaustive however, for instance the speed limit zone signs are generalized even though they differ between the US and European Countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTSD_BASE_PATH = \"/data_2/Datasets/Signs/MTSD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "\n",
    "from sign_names_dict import MTSD_to_carolo\n",
    "\n",
    "\n",
    "def write_mapillary_annotations(data):\n",
    "    traffic_sign_images = glob.glob(os.path.join(MTSD_BASE_PATH, 'images/*'))\n",
    "    traffic_sign_annotations = glob.glob(os.path.join(MTSD_BASE_PATH, 'annotations/*'))\n",
    "    \n",
    "    for image_path, annotation_path in zip(sorted(traffic_sign_images), sorted(traffic_sign_annotations)):\n",
    "        assert image_path.rstrip('.')[0] == annotation_path.rstrip('.')[0]\n",
    "        \n",
    "        with open(annotation_path, 'r') as f:\n",
    "            annotations = json.load(f)\n",
    "            \n",
    "        for annotation in annotations['objects']:\n",
    "            if annotation['label'] in MTSD_to_carolo:\n",
    "                data['Filename'].append(image_path)\n",
    "                data['Roi.X1'].append(annotation['xmin'])\n",
    "                data['Roi.Y1'].append(annotation['ymin'])\n",
    "                data['Roi.X2'].append(annotation['xmax'])\n",
    "                data['Roi.Y2'].append(annotation['ymax'])\n",
    "                data['ClassId'].append(MTSD_to_carolo[annotation['label']])\n",
    "    return data        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Filename': [], 'Roi.X1': [], 'Roi.Y1': [], 'Roi.X2': [], 'Roi.Y2': [], 'ClassId': []}\n",
    "data = write_mapillary_annotations(data)\n",
    "mtsd_df = pandas.DataFrame(data)\n",
    "mtsd_df.to_csv(export_locations['MTSD'], sep=',', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
