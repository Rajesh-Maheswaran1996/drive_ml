{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the Bosch data set\n",
    "\n",
    "This notebook analyzes the Bosch data set and extracts meta-data for further processing from it.\n",
    "\n",
    "\n",
    "The initial labelling file `signs004_ground_truth.csv` contains 16.133 instances with the following data (per row):\n",
    "* Filename\n",
    "* Width\n",
    "* Height\n",
    "* Roi.X1\n",
    "* Roi.Y1\n",
    "* Roi.X2\n",
    "* Roi.Y2\n",
    "* ClassId    \n",
    "\n",
    "The additional labeling files added in April (`signs001_ground_truth.csv`, `signs003_ground_truth.csv`, `signs006_ground_truth.csv`) contain an additional 2.695, 6.421 and 12.870 instances each, respectively. Data ordering remains the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 1) Import and Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mlp\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load sign name dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../sign_recognition/dict/sign_names_dict.pkl', 'rb') as f:\n",
    "    sign_names = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version_info)\n",
    "df = pd.read_csv('signs004_ground_truth.csv')\n",
    "df['ClassId'].replace(sign_names, inplace=True)\n",
    "df.head()  # prints top 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate additionally labeled videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "previously_labeled = 'signs004_ground_truth.csv'\n",
    "\n",
    "frames_added_april = []\n",
    "for filename in os.listdir(os.getcwd()):\n",
    "    if filename.endswith('.csv') and filename != previously_labeled:\n",
    "        frames_added_april.append(pd.read_csv(filename))\n",
    "\n",
    "df_added_april = pd.concat(frames_added_april)\n",
    "df_added_april['ClassId'].replace(sign_names, inplace=True)\n",
    "df_added_april.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2) Plotting the Label Distribution\n",
    "\n",
    "1. First plot shows the distribution over the full dataset (including 'empty' images).\n",
    "2. Second plot illustrates the true label distribution.\n",
    "3. Additional data about the data set (min, max, exact class distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 1) Plot the distribution (with background class).\n",
    "grouped_classes = df.groupby('ClassId').count()['Width']  # Group the dataframe by classes.\n",
    "grouped_classes.plot(kind='bar', figsize=(9,4),  title='Amount of Instances per Class', legend=False)\n",
    "plt.show()\n",
    "\n",
    "# 2) Plot without background class.\n",
    "df_without_background = df.drop(df[df['ClassId'] == sign_names[43]].index)\n",
    "df_without_background_grouped = df_without_background.groupby('ClassId').count()['Width']\n",
    "df_without_background_grouped.plot(kind='bar', figsize=(9,4),  title='Amount of Instances per Class (without Background Class)', legend=False)\n",
    "plt.show()\n",
    "df_without_background_grouped = df_without_background_grouped.reset_index()\n",
    "df_without_background_grouped.columns = ['ClassId', 'Amount']\n",
    "\n",
    "# 3) Print statistics.\n",
    "grouped_classes = grouped_classes.reset_index()  # Makes the index go from 0-17.\n",
    "grouped_classes.columns = ['ClassId', 'Amount']  # Column renaming\n",
    "print(\"  Total Amount: {}\".format(grouped_classes['Amount'].sum()))\n",
    "print(\"Minimum Amount: {}\".format(grouped_classes['Amount'].min()))\n",
    "print(\"Maximum Amount: {}\".format(grouped_classes['Amount'].max()))\n",
    "print(\" Without empty: {}\\n\".format(grouped_classes['Amount'].sum() - grouped_classes['Amount'].max()))\n",
    "print(grouped_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Plot the distribution with the newly added data\n",
    "grouped_original = df.groupby(['ClassId']).count()\n",
    "grouped_new = df_added_april.groupby(['ClassId']).count()\n",
    "df_comparison = pd.concat([grouped_original, grouped_new], axis=0, ignore_index=False)\n",
    "df_comparison['Source'] = (len(grouped_original)*('Initially labeled',) + len(grouped_new)*('Newly added',))\n",
    "df_comparison.reset_index(level=0, inplace=True)\n",
    "df_comparison.rename(columns={'ClassId': 'Class ID'}, inplace=True)\n",
    "df_comparison['Number of labels'] = df_comparison['Filename']\n",
    "df_comparison_wstop = df_comparison.copy()\n",
    "df_comparison_wstop['Class ID'].replace(sign_names, inplace=True)\n",
    "all_classes_plot = sns.factorplot(y='Class ID', x='Number of labels', hue='Source', kind='bar', \n",
    "                                  data=df_comparison_wstop, size=15, palette=\"Set2\", orient='h')\n",
    "all_classes_plot.fig.subplots_adjust(top=0.95)\n",
    "all_classes_plot.fig.suptitle('Amount of Instances per Class (including new labels)', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Plot the distribution with the newly added data, but without the zero class\n",
    "df_comparison.drop(df_comparison[df_comparison['Class ID'] == sign_names[43]].index, inplace=True)\n",
    "df_comparison['Class ID'].replace(sign_names, inplace=True)\n",
    "all_classes_plot = sns.factorplot(y='Class ID', x='Number of labels', hue='Source', kind='bar', \n",
    "                                  data=df_comparison, size=15, palette=\"Set2\", orient='h')\n",
    "all_classes_plot.fig.subplots_adjust(top=0.95)\n",
    "all_classes_plot.fig.suptitle('Amount of Instances per Class (including new labels, without zero class))', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) display total statistics\n",
    "df_all = pd.concat([df, df_added_april])\n",
    "df_all = df_all.groupby('ClassId').count()\n",
    "df_all.drop(sign_names[43], inplace=True)\n",
    "df_all = df_all[['Filename']]\n",
    "df_all.reset_index(inplace=True)\n",
    "df_all.columns = ['Class ID', 'Amount']\n",
    "#df_all['Class ID'].replace(sign_names, inplace=True)\n",
    "df_all.set_index('Class ID', inplace=True)\n",
    "\n",
    "#all_grouped_classes = df_all.groupby('ClassId').count()['Width']  # Group the dataframe by classes.\n",
    "df_all.plot(kind='bar', figsize=(9,4),  title='Amount of Instances per Class (total, no zero class)',\n",
    "            legend=False)\n",
    "plt.show()\n",
    "\n",
    "print(\"  Total Amount: {}\".format(df_all['Amount'].sum()))\n",
    "print(\"Minimum Amount: {}\".format(df_all['Amount'].min()))\n",
    "print(\"Maximum Amount: {}\".format(df_all['Amount'].max()))\n",
    "print(\" Without empty: {}\\n\".format(df_all['Amount'].sum() - grouped_classes['Amount'].max()))\n",
    "print(df_all['Amount'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 4) Clean for \"Time-Axis\"\n",
    "\n",
    "Since all images are taken from a video with 30 fps, most of them show the same scene (even the same pixels with little to no difference to the previous images). This is especially obvious if you inspect a series of images belonging to the same street sign. As a consequence those images yield no variety during training (no generalization) and only amplify overfitting.\n",
    "\n",
    "Therefore, we want to get as much **distinct** images as possible. A trivial approach to achieve this, is to drop all images that are too *close in time* to a *base image*. E.g. a 2 second scene showing a *give way* sign, which corresponds to ~60 images. Given the heuristic, we drop x images that are too close to *image y*. x being 15 and y being the first image in this series, we would only keep the images [1, 16, 31, 46]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to distinguish between images that are to close to one another in time .\n",
    "# e.g. mulitple images from the same 1 second long video snippet.\n",
    "\n",
    "\n",
    "# We want to get the frame time.\n",
    "df_clean = pd.concat([df, df_added_april])\n",
    "df_clean['TrackFrame'] = df_clean['Filename']  # Copy the Filename column.\n",
    "df_clean['TrackFrame'] = df_clean['TrackFrame'].str.extract('(\\d{5})', expand=True).astype(int)  # Extract the frame sequence number.\n",
    "\n",
    "classes = df_without_background_grouped['ClassId'].values  # Get all ClassIds (without background)\n",
    "\n",
    "amount_keep = dict((cl, 0) for cl in classes)\n",
    "amount_drop = dict((cl, 0) for cl in classes)\n",
    "\n",
    "index_to_drop = []\n",
    "\n",
    "for cl in classes:\n",
    "    track_frames = df_clean[df_clean['ClassId'] == cl]['TrackFrame'].values  # Get all FrameIDs.\n",
    "    \n",
    "    running_track_frame = 0\n",
    "    keep_amount, drop_amount = 0, 0\n",
    "    \n",
    "    for track_frame in track_frames:\n",
    "        if (track_frame - running_track_frame) > 15:  # entries to keep\n",
    "            running_track_frame = track_frame\n",
    "            keep_amount += 1\n",
    "        else:  # entries to drop\n",
    "            to_drop = df_clean[(df_clean['ClassId'] == cl) & (df_clean['TrackFrame'] == track_frame)]\n",
    "            drop_amount += 1\n",
    "            index_to_drop.append(to_drop.index.values[0])\n",
    "    \n",
    "    amount_keep[cl] = keep_amount\n",
    "    amount_drop[cl] = drop_amount\n",
    "\n",
    "#print(index_to_drop)\n",
    "df_clean = df_clean.drop(df_clean.index[sorted(index_to_drop)])\n",
    "df_clean = df_clean.drop(df_clean[df_clean['ClassId'] == sign_names[43]].index)\n",
    "        \n",
    "print(\"Images per class that are being kept: \", amount_keep)\n",
    "print(\"\\nImages per class that are being droped: \", amount_drop)\n",
    "\n",
    "print(\"\\nImage-Count before: {}\".format(df_all['Amount'].sum()-grouped_classes['Amount'].max()))\n",
    "print(\"Image-Count after:  {}\".format(len(df_clean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_plot = df_clean.groupby('ClassId').count()['Width']  # Group the dataframe by classes.\n",
    "df_clean_plot.plot(kind='bar', figsize=(9,4),  title='Amount of Instances per Class (after clean-up)', legend=False)\n",
    "plt.show()\n",
    "\n",
    "print(df_clean_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 5) Compare with external datasets\n",
    "\n",
    "Compare previously assembled data with additional signs gathered from existing datasets (in convert_datasets.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_from_datasets = []\n",
    "for filename in os.listdir(os.getcwd()):\n",
    "    if filename.endswith('.csv'):\n",
    "        frames_from_datasets.append(pd.read_csv(filename))\n",
    "        \n",
    "df_labeled = pd.concat(frames_from_datasets)\n",
    "df_labeled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from export_locations import export_locations\n",
    "filenames_from_datasets = export_locations.values()\n",
    "\n",
    "frames_from_datasets = [pd.read_csv(filename) for filename in filenames_from_datasets]\n",
    "\n",
    "df_datasets = pd.concat(frames_from_datasets)\n",
    "df_datasets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_labeled = df_labeled.groupby(['ClassId']).count()\n",
    "grouped_dataset = df_datasets.groupby(['ClassId']).count()\n",
    "df_comparison = pd.concat([grouped_labeled, grouped_dataset], sort=True, axis=0, ignore_index=False)\n",
    "df_comparison['Source'] = (len(grouped_labeled)*('Initially labeled',) + len(grouped_dataset)*('From Datasets',))\n",
    "df_comparison.reset_index(level=0, inplace=True)\n",
    "df_comparison.rename(columns={'ClassId': 'Class ID'}, inplace=True)\n",
    "df_comparison['Number of labels'] = df_comparison['Filename']\n",
    "df_comparison['Class ID'].replace(sign_names, inplace=True)\n",
    "df_comparison.drop(df_comparison[df_comparison['Class ID'] == sign_names[43]].index, inplace=True)\n",
    "all_classes_plot = sns.catplot(y='Class ID', x='Number of labels', hue='Source', kind='bar', \n",
    "                               data=df_comparison, height=15, palette=\"Set2\", orient='h')\n",
    "all_classes_plot.fig.subplots_adjust(top=0.95)\n",
    "all_classes_plot.fig.suptitle('Amount of Instances per Class, manually labeled vs datasets (without zero class)', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
